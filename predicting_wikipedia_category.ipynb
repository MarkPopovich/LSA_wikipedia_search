{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build models that predict one of two categories provided by X and y matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated SVD now available in namespace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use get_dummies, drop first pandas functionality to encode the categories as 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df['target'] = pd.get_dummies(wiki_df['Category'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Machine Learning', 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['Category'].iloc[0], wiki_df['target'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is encoded as category 1, while Business Software is encoded as category 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(wiki_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wiki_svd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97650000000000003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "lr = log_model.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760479041916168"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TFDFI and SVD, predicting a binary class on a corpus of text proves to be a simple matter using only Logistic Regression. The model scores a .976 R2 on test data. \n",
    "\n",
    "The goal of this exercise is to be able to predict a class based on feeding the model a sample of text data from wikipedia. \n",
    "\n",
    "Below I will test my model to see whether it is able to predict class correctly for a single sample of text. In order to do so, I will transform the sample text using tfdfi and svd, and then use the predict function to predict the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = ml_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>_id</th>\n",
       "      <th>categoies</th>\n",
       "      <th>page_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>5a0d0b218423e1001feda37e</td>\n",
       "      <td>[Category:All articles lacking in-text citatio...</td>\n",
       "      <td>2203756</td>\n",
       "      <td>{{More footnotes|date=March 2011}}\\n{{multiple...</td>\n",
       "      <td>Jaccard index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Category                       _id  \\\n",
       "252  Machine Learning  5a0d0b218423e1001feda37e   \n",
       "\n",
       "                                             categoies  page_id  \\\n",
       "252  [Category:All articles lacking in-text citatio...  2203756   \n",
       "\n",
       "                                                  text          title  \n",
       "252  {{More footnotes|date=March 2011}}\\n{{multiple...  Jaccard index  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen sample text here is in the Machine Learning category, cooresponding to numerical category 1. Therefore, the model should predict 1 %97.6 of the time if it is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text['text'] = sample_text['text'].map(str)\n",
    "sample_text['text'] = sample_text['text'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text.set_index('page_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_matrix_spare = tfidf_vector.transform(sample_text['text'])\n",
    "sample_df_tfd = pd.DataFrame(sample_matrix_spare.toarray(),\n",
    "                                index=sample_text.index,\n",
    "                                columns=tfidf_vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_svd_matrix = SVD.transform(sample_df_tfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(sample_svd_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is accurate, predicting 1 or Machine Learning as the category of the text. For brevity I will not prove that the model is accurate 97.6% percent of the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if the functionality was desired, the text would need to be loaded, transformed, and then fed to the model each time. For the purposes of this project I will not do so, but could add that functionality later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that no data leakage is occuring (some of the wiki text reference the category directly in the text body of the page) I will manually copy and paste a text snippet from a random article, ensuring that no data leakage is happening. If them model truly works as well as it scores, it should accurately predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiple issuesrefimprovedateoctober selfpublisheddateoctober advertdateapril infobox software name                    plesk logo                    screenshot              plesk screenshotjpg caption                 something smarter than just plesk screenshot developer               plesk latest release version    latest release date     start date and age operating system        windows linux genre                   web hosting control panel license                 trialware website                 urlpleskcomplesk is a commercial web hosting platform with a control panel that allows a server administrator to set up new websites reseller accounts email accounts and dns entries through a webbased interfaceoriginally designed in novosibirsk russia the hosting automation software was released by plesk inc  and went live first in  overview plesks control panel softwarecontrol panel allows a server system administratoradministrator to set up new websites reseller accounts email accounts and domain name systemdns entries through a web browserwebbased interface  the administrator can create client and site templates which predetermine resourceallocation parameters for the domains andor clients deleted image removed fileplesk  screenshotpngthumbplesk  the latest version of plesk has integrated support for github docker multiserver management and framework ready environment for nodejs php python ruby on rails and more the previous version of plesk  for gnulinuxlinuxunixlikeunix supports multiple posix platforms including debian ubuntu operating systemubuntu centos red hat linux and cloudlinux oscloudlinuxplesk installs custom versions of or manages versions of mysql and postgresql databases microsoft sql server and msdemicrosoft sql server desktop engine under windows apache tomcat java platform server and coldfusion serverthe plesk platform includes extensions for authentication backup software developerdevelopers domain namedomain and dnsplesk is commercial web hosting data center automation software developed for linux and windowsbased commercial hosting service providers plesk was designed to install and manage web hosting systems and applications on a single server the control panel is designed to simplify the management and administration of the web sites by automating various tasks on a single server addons now called plesk extensions plesk has several software packs that are not part of the main plesk code base  these addons are designed to fully interact with plesk and they include docker support git support plesk security advisor multi server extension wordpress toolkit developer pack kaspersky antivirus servershield by cloudflare others httpswwwpleskcomextensions and httpsextpleskcom version history  classwikitable stylefloatcenter margin  em em version releasedplesk onyx march plesk onyx plesk onyx plesk   parallels plesk   parallels plesk panel   parallels plesk panel   parallels plesk panel   parallels plesk panel   plesk   plesk   plesk   security plesk offers users the possibility to easily install web applications using the aps application packaging standard aps packages are updated by the packaging vendor when a security update is made available see also  web hosting control panel comparison of web hosting control panels references reflistemwebmantoolscategoryjava enterprise platformcategoryweb applicationscategorywebsite managementcategoryuser interfacescategoryweb hostingcategoryweb server management software'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df['text'].sample(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"dynamic topic models are generative models that can be used to analyze the evolution of unobserved topics of a collection of documents over time this family of models was proposed by david blei and john lafferty and is an extension to latent dirichlet allocation lda that can handle sequential documentsin lda both the order the words appear in a document and the order the documents appear in the corpus are oblivious to the model whereas words are still assumed to be de finettis theoremexchangeable in a dynamic topic model the order of the documents plays a fundamental role more precisely the documents are grouped by time slice eg years and it is assumed that the documents of each group come from a set of topics that evolved from the set of the previous slicetopicssimilarly to latent dirichlet allocationlda and plsa in a dynamic topic model each document is viewed as a mixture of unobserved topics furthermore each topic defines a multinomial distribution over a set of terms thus for each word of each document a topic is drawn from the mixture and a term is subsequently drawn from the multinomial distribution corresponding to that topicthe topics however evolve over time for instance the two most likely terms of a topic at time matht could be network and zipf in descending order while the most likely ones at time matht could be zipf and percolation in descending ordermodeldefine  as the perdocument topic distribution at time t  as the word distribution of topic k at time t  as the topic distribution for document d in time t  as the topic for the nth word in document d in time t and  as the specific wordin this model the multinomial distributions  respectivelyeven though multinomial distributions are usually written in terms of the mean parameters representing them in terms of the natural parameters is better in the context of dynamic topic modelsthe former representation has some disadvantages due to the fact that the parameters are constrained to be nonnegative and sum to one when defining the evolution of these distributions one would need to assure that such constraints were satisfied since both distributions are in the exponential family one solution to this problem is to represent them in terms of the natural parameters that can assume any real value and can be individually changedusing the natural parameterization the dynamics of the topic model are given byandthe generative process at time slice t is therefore draw topics  draw mixture model  for each document draw  for each word draw topic  draw word where  is a mapping from the natural parameterization x to the mean parameterization namelyinferencein the dynamic topic model only  is observable learning the other parameters constitutes an inference problem blei and lafferty argue that applying gibbs sampling to do inference in this model is more difficult than in static models due to the nonconjugacy of the gaussian and multinomial distributions they propose the use of variational methods in particular the variational kalman filtering and the variational wavelet regressionapplicationin the original paper a dynamic topic model is applied to the corpus of science articles published between  and  aiming to show that this method can be used to analyze the trends of word usage inside topicsref namedtm  the authors also show that the model trained with past documents is able to fit documents of an incoming year better than ldaa continuous dynamic topic model was developed by wang et al and applied to predict the timestamp of documents references\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"forthe arabic term meaning valleywadiinfobox software name                    web application distribution infrastructure logo                     screenshot              caption                 collapsible             developer               apache software foundation status                  active latest release version  wadi snapshot latest release date     release date latest preview version  latest preview date     operating system        crossplatform size                    programming language    java programming languagejava genre                   license                 apache license  website \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix_spare = tfidf_vector.transform(sample_text['text'])\n",
    "test_df_tfd = pd.DataFrame(test_matrix_spare.toarray(),\n",
    "                                columns=tfidf_vector.get_feature_names())\n",
    "test_svd_matrix = SVD.transform(test_df_tfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(test_svd_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing, the model I have trained predicts solely category 1, Machine Learning. Since this happened multiple times on business software text, the model clearly has data leakage. This is due to the fact that the wikitext I have pulled includes at the least the category the text has been pulled from. The model is likely learning the presence of specific category names and simply predicting on these clear indicators of which top level category the subcategories are part of. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
